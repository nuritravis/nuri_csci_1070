{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ccc54c0-c46b-480e-b36e-e39d515de67d",
   "metadata": {},
   "source": [
    "# 1. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "98328516-fd39-426e-806d-847d394b380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "50914d44-25e4-49f4-b2a1-3f7a53290929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ind_ID               int64\n",
       "GENDER              object\n",
       "Car_Owner           object\n",
       "Propert_Owner       object\n",
       "CHILDREN             int64\n",
       "Annual_income      float64\n",
       "Type_Income         object\n",
       "EDUCATION           object\n",
       "Marital_status      object\n",
       "Housing_type        object\n",
       "Birthday_count     float64\n",
       "Employed_days        int64\n",
       "Mobile_phone         int64\n",
       "Work_Phone           int64\n",
       "Phone                int64\n",
       "EMAIL_ID             int64\n",
       "Type_Occupation     object\n",
       "Family_Members       int64\n",
       "label                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "df = pd.read_csv('Credit_Card.csv')\n",
    "label_df = pd.read_csv('Credit_card_label.csv')\n",
    "cc_df = pd.merge(df, label_df, on='Ind_ID')\n",
    "cc_df.dtypes # if its not an int or float its categorical (probably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d93f3117-a45b-4169-b864-a2784bcaf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_count = cc_df.isnull().sum()\n",
    "empty_columns = empty_count[empty_count > 0]\n",
    "empty_columns\n",
    "# dropping occupation because too many values are empty\n",
    "cc_df = cc_df.drop('Type_Occupation', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "9aae8ea6-e4a3-4558-869e-d598d5df3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENDER 2\n",
      "Car_Owner 2\n",
      "Propert_Owner 2\n",
      "Type_Income 4\n",
      "EDUCATION 5\n",
      "Marital_status 5\n",
      "Housing_type 6\n"
     ]
    }
   ],
   "source": [
    "# i want to see how many unique values are in the categorical columns\n",
    "for col in cc_df:\n",
    "    if cc_df[col].dtype == object:\n",
    "        print(col, cc_df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "77c75f2c-73e2-4f37-b86e-34a27c3bd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give all NaN values an appropriate replacement\n",
    "def fill_nan(df: pd.DataFrame, col: str, tendency: str) -> pd.Series:\n",
    "    '''\n",
    "    takes in a dataframe, column, and what value to use in place of NaN values\n",
    "    '''\n",
    "    if tendency == 'mean':\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    elif tendency == 'median':\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    elif tendency == 'mode':\n",
    "        df[col] = df[col].fillna(df[col].mode())\n",
    "\n",
    "# encode all categorical values\n",
    "def encode_cat(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    '''\n",
    "    takes in a dataframe and a categorical column and loops through all unique values. \n",
    "    if the value hasnt already been encoded, it uses the current value as a key and assigns a numerical value to it\n",
    "    '''\n",
    "    val_map = {}\n",
    "    code = 0\n",
    "    for value in df[col].unique():\n",
    "        if value not in val_map:\n",
    "            val_map[value] = code\n",
    "            code+=1\n",
    "    df[col] = df[col].map(val_map)\n",
    "\n",
    "fill_nan(cc_df, 'GENDER', 'mode')\n",
    "fill_nan(cc_df, 'Annual_income', 'median')\n",
    "fill_nan(cc_df, 'Birthday_count', 'mean')\n",
    "encode_cat(cc_df, 'GENDER')\n",
    "encode_cat(cc_df, 'Car_Owner')\n",
    "encode_cat(cc_df, 'Propert_Owner')\n",
    "encode_cat(cc_df, 'Type_Income')\n",
    "encode_cat(cc_df, 'EDUCATION')\n",
    "encode_cat(cc_df, 'Marital_status')\n",
    "encode_cat(cc_df, 'Housing_type')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc8613-7139-48cc-836a-67516a210220",
   "metadata": {},
   "source": [
    "# 2. Univariate Linear Regression \n",
    "using Annual_Income to predict if a credit card application is approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ba271a22-811c-426a-bc6d-5f6543f26505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01587415490612476"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_regression(df: pd.DataFrame, X_col: str, y_col: str) -> float:\n",
    "    \n",
    "    X = np.array(df[X_col]).reshape(-1,1)\n",
    "    y = np.array(df[y_col]).reshape(-1,1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    linear_reg_model = LinearRegression()\n",
    "    linear_reg_model.fit(X_train, y_train)\n",
    "    y_pred = linear_reg_model.predict(X_test)\n",
    "    \n",
    "    r2 = linear_reg_model.score(X_test, y_test)\n",
    "    return r2\n",
    "linear_regression(cc_df, 'Annual_income', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c0fce-b8fb-42df-a1c6-601e4d67cc93",
   "metadata": {},
   "source": [
    "A score of -0.016 means the model performed very poorly. The problem stems from linear regression being designed for linear, continuous values, and in this context we're trying to predict a nonlinear, discrete outcome. So, linear regression isn't suitable for this dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed4b55-6d3a-4c5b-9235-b8b457c2925a",
   "metadata": {},
   "source": [
    "# 3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "69e5757b-d1e2-4245-8306-6c1d4c372167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9075268817204301, 2)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimal_knn() -> float:\n",
    "    '''\n",
    "    we can find the optimal k value by calculating the accuracy score for each value of k \n",
    "    in a predetermined range and returning the value that gives us the best score\n",
    "    we can then use that value to perform KNN \n",
    "    '''\n",
    "    X = cc_df.drop('label', axis=1)\n",
    "    y = cc_df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    high_score = 0\n",
    "    opt_k = 0\n",
    "    for k in range(1, 20):\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        score = knn.score(X_test, y_test)\n",
    "        if score > high_score:\n",
    "            high_score = score\n",
    "            opt_k = k \n",
    "    return high_score, opt_k\n",
    "    \n",
    "optimal_knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a2901-cc72-417c-96ed-63cc45fd8c2c",
   "metadata": {},
   "source": [
    "The KNN model performed extremely well with an accuracy score of 0.91. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0cacc9-69e7-4f35-a01b-d54f4ee5f23f",
   "metadata": {},
   "source": [
    "# 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "51cf439e-1355-4fe9-9bc1-476ff200829b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075268817204301"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic_regression() -> float:\n",
    "    X = cc_df.drop('label', axis=1)\n",
    "    y = cc_df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    regression = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    r2=regression.score(X_test, y_test)\n",
    "    return r2\n",
    "    \n",
    "logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c5d4e-06e6-4b72-8053-9cda29b3df05",
   "metadata": {},
   "source": [
    "The logistic regression model had the same outcome as KNN with a score of 0.91. both models made mostly accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bd8bf-cbc4-4250-b141-95fe2def2aaf",
   "metadata": {},
   "source": [
    "# 5. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "759fbc93-b806-4984-9d8d-a0b0288b70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(df: pd.DataFrame, X_col: str, y_col: str) -> float:\n",
    "    \n",
    "    X = np.array(df[X_col]).reshape(-1,1)\n",
    "    y = np.array(df[y_col]).reshape(-1,1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    X_train = sc.fit_transform(X_train) \n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    linear_reg_model = LinearRegression()\n",
    "    linear_reg_model.fit(X_train, y_train)\n",
    "    y_pred = linear_reg_model.predict(X_test)\n",
    "    \n",
    "    r2 = linear_reg_model.score(X_test, y_test)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6b9a9325-e865-4fd6-8ff1-028c7519bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_knn() -> float:\n",
    "    X = cc_df.drop('label', axis=1)\n",
    "    y = cc_df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    X_train = sc.fit_transform(X_train) \n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    high_score = 0\n",
    "    opt_k = 0\n",
    "    for k in range(1, 20):\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        score = knn.score(X_test, y_test)\n",
    "        if score > high_score:\n",
    "            high_score = score\n",
    "            opt_k = k \n",
    "    return high_score, opt_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "510e7e48-05a7-4520-beac-e67250758e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression() -> float:\n",
    "    X = cc_df.drop('label', axis=1)\n",
    "    y = cc_df['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    X_train = sc.fit_transform(X_train) \n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    regression = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    r2=regression.score(X_test, y_test)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "39808cac-4a58-408b-9087-290d48ec4edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.01704379390288069, (0.9096774193548387, 2), 0.9075268817204301)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(cc_df, 'Annual_income', 'label'), optimal_knn(), logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec31af-c57b-4257-81d9-82bd98fc2e39",
   "metadata": {},
   "source": [
    "After normalizing the data, the following things happened:\n",
    " - linear regression had slightly lower accuracy\n",
    "\n",
    " - KNN had slightly higher accuracy\n",
    "\n",
    "\n",
    " - logistic regression had the same accuracy score\n",
    "\n",
    "I think accuracy is the best measure of performance for this dataset because our goal is to *accurately* predict who had their application approved. Precision and recall are less important here because the stakes are low for false predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
